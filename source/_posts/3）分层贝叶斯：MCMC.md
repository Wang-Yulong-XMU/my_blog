---
title: 分层贝叶斯（3）：MCMC——理论与现实的桥梁
date: 2025-10-07 16:13

category: 算法

katex: true
cover: /img/bys.png
---

# ⚙️ 分层贝叶斯：MCMC——复杂后验的采样

## 引言：当贝叶斯遇到“维度灾难”

在前两篇文章中，我们了解了贝叶斯推断的基础（先验、似然、后验）以及分层贝叶斯模型（HBM）如何通过**超参数 $\alpha$** 实现信息共享。

分层模型虽然强大，但也带来了巨大的计算挑战。回想贝叶斯定理：

$$P(\theta|D) \propto P(D|\theta) P(\theta)$$

当我们有 $M$ 个局部参数 $\theta_m$ 和超参数 $\alpha$ 时，我们需要推断的是一个关于 $(\theta_1, \dots, \theta_M, \alpha)$ 的**联合后验分布**。在现实模型中，这个参数空间可能有数百甚至数千个维度。

* **挑战：** 这种高维的后验分布 $P(\theta|D)$ 形状复杂、多峰，**无法通过传统的解析积分求解**。  
* **解决方案：** 我们需要一种方法来“近似”这个复杂的分布——这就是 **马尔可夫链蒙特卡洛（Markov Chain Monte Carlo, MCMC）** 采样方法。

---

## 一、从积分到采样：用“频率”逼近“密度”

### 1. 从积分的痛点说起

贝叶斯推断的核心在于后验分布：

$$P(\theta|D) = \frac{P(D|\theta)P(\theta)}{P(D)}$$

其中分母：

$$P(D) = \int P(D|\theta)P(\theta)\, d\theta$$

通常无法解析求解。  
于是我们希望通过**随机采样**来逼近这个积分。

如果我们能够从后验分布 $P(\theta|D)$ 中采样得到点集 $\{\theta^{(1)}, \dots, \theta^{(N)}\}$，那么任意函数的期望就可以近似为：

$$\mathbb{E}[f(\theta)] \approx \frac{1}{N}\sum_{i=1}^N f(\theta^{(i)})$$

换句话说：  
**积分太难？那就通过采样求平均。**

---

### 2. 蒙特卡洛（Monte Carlo）的思想

蒙特卡洛方法用随机抽样替代复杂计算。  
例如：要估计一个复杂形状区域的面积，只需在外接正方形中随机撒点，通过落入目标区域的比例估算面积。

同样地，在贝叶斯推断中，我们通过**样本频率**近似**概率密度**。  
样本在后验高密度区域出现得更频繁，自然反映了后验分布的形状。

---

## 二、MCMC 的核心：让样本“走向后验”

### 1. 马尔可夫链：带有记忆衰减的随机游走

马尔可夫链是一种**无记忆性随机过程**：

$$P(\theta^{(t+1)}|\theta^{(t)}, \theta^{(t-1)}, \dots) = P(\theta^{(t+1)}|\theta^{(t)})$$

MCMC 的目标是构造这样一条链，使其在长期运行后，状态分布稳定地收敛到目标分布 $P(\theta|D)$。  
只要链是**不可约（Irreducible）**、**非周期（Aperiodic）且满足平稳性（Stationarity）**，采样点就能代表后验分布。

> MCMC 让链在高概率区域停留更久，低概率区域更快离开。  
> 链走得越久，样本分布越接近真实后验。

---

### 2. Metropolis–Hastings 算法（MH）

MH 是最经典的 MCMC 算法。  
它通过“提出–接受–拒绝”的机制实现采样：

1. **初始化** $\theta^{(0)}$。  

2. **提出候选样本** $\theta'$，从提议分布 $q(\theta'|\theta^{(t)})$ 生成。  

3. **计算接受率：**
   
   $$r = \frac{P(D|\theta') P(\theta') q(\theta^{(t)}|\theta')}{P(D|\theta^{(t)}) P(\theta^{(t)}) q(\theta'|\theta^{(t)})}$$

4. **接受或拒绝：**
   
   $$ \theta^{(t+1)} =\begin{cases}\theta', & \text{以概率 } \min(1, r) \text{ 接受}\\\theta^{(t)}, & \text{否则保持不变}\end{cases}$$

5. 重复迭代直到收敛。

在充分运行后，样本序列 $\{\theta^{(1)}, \dots, \theta^{(N)}\}$ 就服从目标后验分布。

## 三、从采样到统计：如何“读懂”后验样本

当 MCMC 完成采样后，我们获得一系列后验样本：  
$\{\theta^{(1)}, \theta^{(2)}, \dots, \theta^{(S)}\}$。

### 后验统计量估计

| 统计量      | 数学定义                                 | 采样近似                                                |
|:-------- |:------------------------------------ |:--------------------------------------------------- |
| 后验均值     | $\mathbb{E}[\theta\|D]$              | $\frac{1}{S}\sum_s \theta^{(s)}$                    |
| 方差       | $\text{Var}[\theta\|D]$              | $\frac{1}{S}\sum_s (\theta^{(s)} - \bar{\theta})^2$ |
| 95% 可信区间 | $[\theta_{2.5\\%},\theta_{97.5\\%}]$ | 样本分位数估计                                             |

这些结果提供了参数估计与不确定性量化。

---

## 四、从采样到预测：贝叶斯式前瞻

MCMC 的威力不仅在于“知道参数”，更在于“用参数预测未来”。

### 1. 贝叶斯预测分布

$$P(\tilde{D}|D) = \int P(\tilde{D}|\theta) P(\theta|D)\, d\theta$$

利用采样点近似：

$$P(\tilde{D}|D) \approx \frac{1}{S} \sum_{s=1}^S P(\tilde{D}|\theta^{(s)})$$

### 2. 实现步骤

1. 从后验样本集中随机选取 $\theta^{(s)}$。  
2. 代入似然函数 $P(\tilde{D}|\theta^{(s)})$，生成预测数据。  
3. 汇总所有模拟结果，得到预测分布 $P(\tilde{D}|D)$。  

这种方法自然地将参数不确定性传播到预测结果中，使预测更加稳健。

---

## 五、小结：让不可算的积分变得可行

| 阶段     | 目标                         | MCMC 的作用      |
| ------ | -------------------------- | ------------- |
| 参数推断   | $P(\theta\|D)$             | 构造马尔可夫链采样逼近后验 |
| 不确定性评估 | $\mathbb{E}[f(\theta)\|D]$ | 用采样均值替代积分     |
| 预测阶段   | $P(\tilde{D}\|D)$          | 基于后验样本模拟未来数据  |

> ***MCMC 是贝叶斯思想的与现实的桥梁。**  
> 它让“不可积”的概率世界，通过采样变得可触、可算、可解释。
