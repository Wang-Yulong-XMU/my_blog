---
title: 分层贝叶斯（1）：朴素贝叶斯
date:  2025-10-06 16:55
category: 算法
katex: true

cover: /img/bys.png

---

# 🚀 分层贝叶斯（一）：朴素贝叶斯

## 引言：当“信念”遇到“数据”

在日常生活中，我们经常根据新的观察来修正自己的看法或信念。**贝叶斯方法**正是将这种人类的认知过程——**信念的更新**——用严谨的数学公式固定下来。

在机器学习和统计学中，贝叶斯定理提供了一个强大的框架来**量化不确定性**，并根据数据对模型参数进行推断。

我们将从最简单的 **朴素贝叶斯（Naive Bayes）** 分类器入手，通过一个经典的**抛硬币实验**，先彻底理解贝叶斯公式中的三大核心要素：**先验、似然和后验**。

---

## 一、引子：抛硬币实验

想象你手里有一枚硬币，您想知道它**正面向上的真实概率** $\theta$ 是多少。这个 $\theta$ 就是我们模型中的**参数（Parameter）**，它是我们想要推断的、不可直接观测的“真相”。

### 1. 初始信念：先验分布 $P(\theta)$

在抛硬币之前，我们对这枚硬币的真实概率 $\theta$ 是有**初始信念**（即先验）的。

* **概念：** **先验分布（Prior Distribution）** $P(\theta)$ 描述了在观测到任何数据之前，我们对参数 $\theta$ **所有可能取值的不确定性**和**初始信念**。
* **数学形式：** **先验必须是一个概率分布（Distribution），而非单个数值。** 它用数学函数量化了我们认为 $\theta$ 更可能在哪个范围（如 $\text{Beta}(1, 1)$ 表示均匀分布，即对 $\theta$ 一无所知）。在抛硬币这里，出于经验学，我们可以认为真实概率 $\theta$ 不会过多的偏离 $0.5$，这即为先验。

### 2. 数据支持度：似然函数 $P(D|\theta)$

假设我们观察到了这样的一个事实：抛了 $N$ 次硬币，得到了 $k$ 次正面（数据 $D$）。

* **概念：** **似然函数（Likelihood Function）** $P(D|\theta)$ 描述了在**给定一个特定的参数 $\theta$ 时**，观测到当前这组数据 $D$ 的**概率值**。
* **作用：** 它是数据对不同 $\theta$ 值的**支持度**。似然值越高，表明这个 $\theta$ 值越能解释我们观察到的数据。
* **注意：** 似然 $P(D|\theta)$ 本质上是一个关于 $\theta$ 的函数，它**不要求归一化**，**不**是一个关于 $\theta$ 的概率分布。

在这个引子中，案例：如何计算似然 $P(D|\theta)$ 抛硬币的数据生成过程符合**二项分布（Binomial Distribution）**。
似然函数 $P(D|\theta)$ 的数学形式是：

$$P(D|\theta) = \binom{N}{k} \theta^k (1-\theta)^{N-k}$$

### 3. 更新后的信念：后验分布 $P(\theta|D)$

结合了的初始信念（先验）和观测到的数据（似然）后，我们对 $\theta$ 的认识得到了修正。

* **概念：** **后验分布（Posterior Distribution）** $P(\theta|D)$ 描述了在观测到数据 $D$ 之后，我们对参数 $\theta$ **更新后的信念**。
* **物理意义：** 后验分布是**先验信息**和**数据信息**（似然）之间**妥协和整合**的结果。数据量越少，后验越接近先验；数据量越大，后验越由数据（似然）主导。

---

## 二、贝叶斯定理与朴素贝叶斯公式

### 1. 贝叶斯定理：信念更新的公式

这三个概念通过贝叶斯定理联系起来：

$$P(\theta|D) = \frac{P(D|\theta) P(\theta)}{P(D)}$$

公式中的分母 $P(D)$ 被称为**证据（Evidence）** 或**边缘似然（Marginal Likelihood）**。

### 2. 证据 $P(D)$ 的作用与意义

* **作用：** $P(D)$ 的作用是确保后验分布 $P(\theta|D)$ 的总积分等于 $1$（即归一化常数）。
* **推断聚焦：** 在推断参数 $\theta$ 的后验分布时，我们通常只关注分子即似然函数和先验的联合概率密度，因为**后验的形状**完全由分子决定：

$$P(\theta|D) \propto P(D|\theta) P(\theta)$$

* **模型选择意义：** 证据 $P(D)$ 的数值大小，直接决定了该模型在解释观测数据方面的好坏程度。

### 3. 朴素贝叶斯的“理想性”

朴素贝叶斯分类器应用贝叶斯定理来计算给定特征 $X$ 时属于类别 $C$ 的概率 $P(C|X)$。

* **核心问题：** 在实际分类问题中，计算 $P(X|C)$（似然）非常复杂，因为特征 $X = \{x_1, x_2, \dots, x_n\}$ 通常有很多维度且相互关联。
* **朴素的简化：** 朴素贝叶斯模型做了一个**理想性**假设：**给定类别 $C$ 的条件下，所有特征 $x_i$ 之间是相互独立的。**

$$P(X|C) = P(x_1, x_2, \dots, x_n|C) = \prod_{i=1}^n P(x_i|C)$$

虽然这个独立性假设在现实中**几乎不可能完全成立**（因此被称为“朴素”），但它极大地简化了计算，使得朴素贝叶斯在文本分类等简单场景中依然非常高效和实用。
